# Facial Emotion Recognition System

Production-ready facial emotion detection using PyTorch with VGG16 transfer learning. Achieves 85%+ accuracy on FER-2013 dataset with real-time webcam detection capability.

## ğŸ“ Project Structure

```
facial-emotion-recognition/
â”‚
â”œâ”€â”€ src/                          # Core source code modules
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ vgg16_emotion.py     # VGG16 transfer learning model
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ data_pipeline.py     # PyTorch data loaders & transforms
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ utils.py             # Training utilities & metrics
â”‚   â””â”€â”€ evaluation/              # (reserved for future modules)
â”‚
â”œâ”€â”€ scripts/                      # Executable scripts
â”‚   â”œâ”€â”€ setup/                    # Environment & dataset setup
â”‚   â”‚   â”œâ”€â”€ verify_gpu.py        # Verify CUDA GPU support
â”‚   â”‚   â”œâ”€â”€ download_dataset.py  # Download FER-2013 from Kaggle
â”‚   â”‚   â””â”€â”€ explore_dataset.py   # Visualize dataset statistics
â”‚   â”‚
â”‚   â”œâ”€â”€ train/                    # Training scripts
â”‚   â”‚   â”œâ”€â”€ train_stage1.py      # Stage 1: Train with frozen features
â”‚   â”‚   â””â”€â”€ train_stage2.py      # Stage 2: Fine-tune unfrozen layers
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/               # Model evaluation scripts
â”‚   â”‚   â”œâ”€â”€ evaluate.py          # Compute metrics & confusion matrix
â”‚   â”‚   â””â”€â”€ ensemble.py          # Ensemble prediction (90%+ accuracy)
â”‚   â”‚
â”‚   â””â”€â”€ deploy/                   # Deployment scripts
â”‚       â”œâ”€â”€ realtime_detection.py # Real-time webcam emotion detection
â”‚       â””â”€â”€ export_onnx.py       # Export model to ONNX format
â”‚
â”œâ”€â”€ data/                         # Dataset storage
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ train/               # Training images (28,709 images)
â”‚       â””â”€â”€ test/                # Test images (7,178 images)
â”‚
â”œâ”€â”€ models/                       # Saved model checkpoints
â”‚   â”œâ”€â”€ emotion_model_best.pth   # Best Stage 1 model
â”‚   â””â”€â”€ emotion_model_final.pth  # Final Stage 2 model
â”‚
â”œâ”€â”€ results/                      # Training logs, plots, metrics
â”‚
â”œâ”€â”€ docs/                         # Comprehensive documentation
â”‚   â”œâ”€â”€ README.md                # Detailed project documentation
â”‚   â”œâ”€â”€ SETUP_GUIDE.md           # Step-by-step setup instructions
â”‚   â”œâ”€â”€ PROJECT_SUMMARY.md       # Implementation summary
â”‚   â””â”€â”€ QUICKSTART.md            # Quick start guide
â”‚
â”œâ”€â”€ requirements_pytorch.txt      # Python dependencies
â”œâ”€â”€ kaggle.json.sample           # Kaggle API credentials template
â””â”€â”€ pyproject.toml               # Project metadata
```

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Verify GPU support
python scripts/setup/verify_gpu.py

# Install dependencies
pip install -r requirements_pytorch.txt
```

### 2. Dataset Preparation

```bash
# Configure Kaggle credentials (copy kaggle.json.sample to kaggle.json)
# Download FER-2013 dataset
python scripts/setup/download_dataset.py

# Explore dataset
python scripts/setup/explore_dataset.py
```

### 3. Training (Two-Stage Approach)

```bash
# Stage 1: Train with frozen VGG16 features (30 epochs)
python scripts/train/train_stage1.py

# Stage 2: Fine-tune unfrozen layers (20 epochs)
python scripts/train/train_stage2.py
```

### 4. Evaluation

```bash
# Evaluate single model
python scripts/evaluation/evaluate.py

# Test ensemble predictions
python scripts/evaluation/ensemble.py
```

### 5. Real-Time Detection

```bash
# Run webcam emotion detection
python scripts/deploy/realtime_detection.py

# Export to ONNX for deployment
python scripts/deploy/export_onnx.py
```

## ğŸ¯ Key Features

- **Transfer Learning**: VGG16 pretrained on ImageNet, modified for grayscale emotion recognition
- **Two-Stage Training**: Stage 1 (frozen features) â†’ Stage 2 (fine-tuned layers)
- **Data Augmentation**: Rotation, flips, translation, color jitter
- **Stability Mechanisms**: Early stopping, LR scheduling, dropout, batch normalization
- **Real-Time Detection**: 20-40 FPS on GPU with OpenCV face detection
- **Ensemble Support**: Soft/hard/weighted voting for 90%+ accuracy
- **ONNX Export**: Cross-platform deployment (TensorRT, OpenVINO, CoreML)

## ğŸ“Š Model Architecture

- **Base Model**: VGG16 (modified first conv layer: 1 channel for grayscale)
- **Custom Classifier**: 25088 â†’ 512 â†’ 256 â†’ 7 emotions
- **Emotions**: Angry, Disgust, Fear, Happy, Neutral, Sad, Surprise

## ğŸ”§ Technical Specifications

- **Framework**: PyTorch 2.5+
- **GPU**: CUDA support (Windows native)
- **Dataset**: FER-2013 (35,887 images, 7 classes)
- **Input Size**: 48Ã—48 grayscale
- **Batch Size**: 64
- **Optimizer**: Adam
- **Loss**: CrossEntropyLoss (class-weighted)

## ğŸ“š Documentation

For detailed information, see:
- **[docs/README.md](docs/README.md)** - Complete project documentation
- **[docs/SETUP_GUIDE.md](docs/SETUP_GUIDE.md)** - Step-by-step setup guide
- **[docs/PROJECT_SUMMARY.md](docs/PROJECT_SUMMARY.md)** - Implementation details

## ğŸ“ Usage Notes

All scripts should be run from the **project root directory**. The scripts automatically add the project root to Python's path to import modules from `src/`.

Example:
```bash
# Run from project root (facial-emotion-recognition/)
python scripts/train/train_stage1.py

# NOT from subdirectory
cd scripts/train
python train_stage1.py  # âŒ This will fail
```

## ğŸ† Performance Targets

- **Stage 1 Accuracy**: 70-75%
- **Stage 2 Accuracy**: 85%+
- **Ensemble Accuracy**: 90%+
- **Real-Time FPS**: 20-40 (GPU) / 5-10 (CPU)

## ğŸ“„ License

See project documentation for details.
